---
layout: post
title: "데이터 중심 애플리케이션 설계 10장 - 일괄 처리"
tags:
- data
- book
category:
- data
---
* toc
{:toc}

# 일괄 처리

현재는 요청/응답 방식의 상호작용이 매우 흔해져, 이를 당연한 것으로 여기기 쉽지만 이것이 시스템을 구축하기 위한 유일한 방법은 아니다. 시스템을 다음 세 가지로 나누어 보자

- 서비스(온라인 시스템)
    + 서비스는 클라이언트로부터 요청이 올 때까지 대기
    + 요청이 오면 가능한 빠르게 요청을 처리해서 응답을 반환
    + **응답 시간이 중요한 지표. 때로는 가용성이 중요하다.**
- 일괄 처리 시스템(오프라인 시스템)
    + 매우 큰 입력 데이터를 받아서 데이터를 처리하는 작업을 수행하고, 결과 데이터를 생상한다.
    + 매우 오래 걸릴 수 있어서(수 분에서 수 일), 대게 사용자가 작업이 끝날 때까지 대기하지 않는다.
    + 하루에 한번 수행과 같이 반복적인 일정으로 처리한다.
    + **처리량이 대표적인 지표**
- 스트림 처리 시스템(준실시간 시스템)
    + 일괄 처리 시스템처럼 요청에 대해 바로 응답하지 않는다.
    + 입력 데이터를 소비하고 출력 데이터를 생산한다.
    + 입력 데이터가 입력되면 바로 작동한다. 이런 특성 떄문에 일괄 처리 시스템보다 지연 시간이 낮다.

이 장에서는 일괄 처리를 살펴볼 것이고, 대표적으로 맵리듀스(MapReduce) 라는, 2004년도에 발표된 일괄 처리 알고리즘을 살펴볼 것이다. 지금은 맵리듀스의 중요성이 떨어지고 있지만, 왜 일괄 처리가 유용한지 명확하게 그림을 그려주기 때문에 맵리듀스를 이해할 가치는 충분하다.

그러나 그 이전에, 먼저 유닉스 도구를 사용해 데이터를 처리하는 방법을 살펴본다. 유닉스가 주는 아이디어와 교훈이 대규모 이기종 분산 시스템에도 그대로 이어지기 떄문이다.

## 유닉스 도구로 일괄 처리하기

웹서버가 하나 있고, 들어온 요청이 처리될 때마다 로그 파일이 한 줄씩 추가된다고 가정하자. 실제로는 한 줄인데 가독성을 위해 여러 줄로 나타냈다.

~~~text
216.58.210.78 -- [27/Feb/2015:17:55:11 +0000] " GET IcssItypography.css HTTP/1.1" 
200 3377 "http://martin.kleppmann.com/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 
10_9_5) AppleWebKit/537.36 (KHTML, like Gecko) ChromeI40.0.2214.115 
Safari/537.36"
~~~

이 줄에는 많은 정보가 들어있다. 해석하려면 로그 형식의 정의가 필요하다.

~~~text
$remote_addr - $remote_user [$time_local] "$request"
$status $body_bytes_sent "$http_referer" "$http_user_agnet"
~~~

이 정보를 가지고 위의 로그를 해석할 수 있다.

## 단순 로그 분석

기본 유닉스 도구를 활용하여 로그를 처리하고, 웹사이트 트래픽에 대한 보고서를 만들 수 있다. 예를 들어 웹사이트에서 가장 인기가 높은 페이지 5개를 뽑는다면 다음과 같이 할 수 있다.

~~~bash
cat /var/log/nginx/acess.log    |
    awk '{print $7}'            |
    sort                        |
    uniq -c                     |
    sort -r -n                  |
    head -n -5                  |
~~~

다음과 같이 줄마다 해석할 수 있다.

1. 로그를 읽는다.
2. 줄마다 공백으로 분리하여 요청 URL 에 해당하는 7번째 필드를 분리한다.
3. 알파뱃 순으로 정렬한다.
4. 중복을 제거한다. -c 는 중복 횟수를 출력하는 옵션이다. 즉 각 URL 마다 몇 번 호출되었는지 확인한다.
5. -n 을 활용하여 요청 순으로 다시 정렬한다.
6. 상위 5줄을 출력한다.

유닉스 도구에 익숙하지 않다면 이해하기 쉽지 않다. 하지만 이런 방식은 상당히 강력하다. 수 기가 바이트의 로그 파일을 수 초 내로 처리할 수 있고, 필요에 따라 분석 방법을 변경하기도 쉽다.
많은 데이터 분석을 수 분 내에 awk, sed, grep, sort, uniq, xargs 의 조합으로 결과를 출력할 수 있고, 놀라울 정도로 잘 수행된다.

## 연쇄 명령 대 맞춤형 프로그램

스크립트를 사용하여 로그를 출력할 수 있다. 파이썬이나 루비와 같은 도구를 활용하여 스크립트를 짜면, 간결하지는 않지만 더 읽기 쉽다. 두 방법 중 하나를 선택하는 것은 취향의 문제다. 그러나, 표면적인 문법의 차이를 빼고도 두 방법은 실행 흐름이 크게 다르다.

1. 스크립트는 URL 해시 테이블을 메모리에 유지한다.
2. 유닉스 파이프라인에는 이런 해시 테이블이 없는 대신에, 정렬된 목록에 같은 URL 이 반복하여 나타난다.

어느 방법이 더 좋을까? 상황에 다라 다르다. 중소 규모의 웹사이트 대부분은 고유 URL 과 카운트를 대략 1GB 메모리에 올릴 수 있다. 작업 세트가 충분히 작다면 인메모리 해시 테이블도 잘 작동한다. 노트북이라도 충분하다.

반면 허용 메모리보다 작업 세트가 크다면 정렬 접근법을 사용하는 것이 좋다. 이는 디스크를 좀 더 효율적으로 사용할 수 있다. 다음과 같은 흐름으로 작업이 진행된다.

1. 데이터 청크를 메모리에 정렬한다.
2. 청크를 세그먼트 파일로 디스크에 저장한다.
3. 정렬된 세그먼트 파일 여러 개를 한 개의 큰 파일로 병합한다.

GNU Coreutils 에 포함된 sort 유틸리티는 메모리보다 큰 데이터셋은 자동으로 디스크로 보내고 멀티 CPU 코어에서 병렬로 정렬한다. 이는 메모리 문제 없이 큰 파일을 정렬할 수 있다는 의미이다. 병목이 있다면 아마도 디스크에서 입력 파일을 읽는 속도일 것이다.

## 유닉스 철학

유닉스 철학은 다음과 같다.


> 1. 각 프로그램이 한 가지 일만 하도록 작성하라. 새 작업을 하려면 기존 프로그램을 고쳐 새로운 "기능"을 추가해 프로그램을 복잡하게 만들기보다는 새로운 프로그램을 작성하라
> 2. 모든 프로그램의 출력은 아직 알려지지 않은 다른 프로그램의 입력으로 쓰일 수 있다고 생각하라. 불필요한 정보로 출력이 너저분해져서는 안 된다. 입력 형식으로 엄격하게 열을 맞춘다던가 이진 형태를 사용하지 마라. 대화형 입력을 고집하지 마라
> 3. 소프트웨어를 빠르게 써볼 수 있게 설계하고 구축하라. 심지어 운영체제도 마찬가지다. 수 주 안에 끝나는 것이 이상적이다. 거슬리는 부분은 과감히 버리고 새로 구축하라.
> 4. 프로그래밍 작업을 줄이려면 미숙한 도움보다 도구를 사용하라. 도구를 빌드하기 위해 한참 둘러가야 하고 게다가 사용 후 바로 버린다고 할지라도 도구를 써라.

**자동화, 빠른 프로토타이핑, 증분 반복, 실험 친화, 큰 프로젝트를 청크로 나누어 처리하기와 같은 방버븝 오늘날의 애자일 및 데브옵스 운동과 매우 흡사하고 놀랍게도 40년이 지났지만 거의 바뀌지 않았다.**

sort 가 위의 조건을 잘 지킨 프로그램의 훌륭한 예이다. 그러나 sort 는 단독으로는 별로 유용하지 않다. uniq 와 같은 다른 유닉스 도구와 조합해서 사용했을 때 비로소 강력해진다.
유닉스에 이런 결합성을 부여하는 것은 무엇일까?

### 동일 인터페이스

특정 프로그램이 다른 **어떤** 프로그램과도 연결 가능하려면, 프로그램 **모두**가 같은 입출력 인터페이스를 사용해야 한다. 유닉스에서의 인터페이스는 파일(정확히는 파일 디스크립터)이다. 파일은 단지 순서대로 정렬된 바이트의 연속이다. 파일은 이처럼 단순해서 같은 인터페이스로 파일시스템의 실제 파일, 프로세스 간의 통신 채널(유닉스 소켓, 표준 입력(stdin), 표준 출력(stdout)), 장치 드라이버(/dev/audio, /dev/lp0), TCP 연결을 나타내는 소켓 등 다른 여러 가지 것을 표현할 수 있다. 당연하게 받아들이기 쉽지만, 여러 이질적인 것들이 하나의 동일 인터페이스를 공유한다는 점은 사실 꽤나 주목할 만 하다. 그렇지 않다면 쉽게 서로 연결하기 어려울 것이다.

완벽하지 않음에도, 심지어 수십 년이 지나썽도 유닉스의 동일 인터페이스는 여전히 대단하다. 유닉스만큼 이를 잘 하는 소프트웨어는 많지 않다.

### 로직의 연결과 분리

유닉스 도구의 다른 특징으로 표준 입력(stdin) 과 표준 출력(stdout) 을 사용한다는 점을 들 수 있다. 프로그램을 실행하고 아무것도 설정하지 않는다면, 표준 입력은 키보드로부터 들어오고 표준 출력은 화면으로 나간다. 혹은 파일에서 입력을 가져와 다른 파일로 출력을 재전송할 수도 있다. 이 때 중간 데이터를 디스크에 쓰지 않고 작은 인메모리 버퍼를 사용하여 프로세스 간 데이터를 전송한다. 프로그램이 특정 파일에 경로에 신경쓰지 않고 stdin 과 stdout 으로 처리하고 싶다면, 유닉스 접근법이 가장 좋다. 프로그램은 입력이 어디서부터 들어오는지 출력이 어디로 나가는지 신경 쓰거나 알 필요조차 없다.

### 투명성과 실험

- 유닉스 명령에 들어가는 입력 파일은 일반적으로 불변이다. 이것은 다양한 명령행 옵션을 사용하여 명령을 수행하더라도, 입력 파일에는 손상을 주지 않는다는 의미이다.
- 어느 시점이든 디버깅을 중단하고 출력을 파이프를 통해 less 로 보내 확인할 수 있다.
- 특정 파이프라인의 출력을 파일에 쓰고, 그 파일을 다음 단계의 입력으로 사용할 수 있다. 이렇게 하면 전체 파이프라인을 다시 시작하지 않고 중간 지점부터 다시 파이프라인을 진행할 수 있다.

유닉스 도구는 관계형 데이터베이스의 질의 최적화 도구와 비교하면 상당히 불친절하고 단순하지만, 이처럼 놀라울 정로로 유용하다. 특히 실험용으로 아주 좋다.

**유닉스 도구를 사용하는 데 가장 큰 제약은 단일 장비에서만 실행된다는 점이다. 바로 이 점이 하둡 같은 도구가 필요한 이유다.**

## 맵리듀스와 분산 파일 시스템

맵리듀스는 다음과 같은 특징을 가진다.

- 유닉스 도구와 비슷하지만 수천 대의 장비로 분산하여 실행이 가능하다.
- 하나 이상의 입력을 받아 하나 이상의 출력을 만들어낸다.
- 맵리듀스 작업은 입력을 수정하지 않는다. 출력 파일은 순차적으로 한 번만 쓰여지고 파일에 이미 쓰여진 부분은 고치지 않는다.
- 분산 파일 시스템상의 파일을 입력과 출력으로 사용한다. 이 파일 시스템은 HDFS(Hadoop Distributed File System) 이라고 하는데, GFS 를 재구현한 오픈소스이다.

HDFS는 각 장비에서 실행되는 데몬 프로세스로 구성된다. 데몬 프로세스는 다른 노드가 해당 장비에 저장된 파일에 접근 가능하게끔 네트워크 서비스를 제공한다. **네임노드**라고 부르는 중앙 서버는 특정 파일 블록이 어떤 장비에 저장됐는지 추척한다. 따라서 HDFS는 **개념적으로는 매우 큰 하나의 파일 시스템이고 데몬이 실행 중인 장비의 모든 디스크를 사용할 수 있다.**

장비가 죽거나 디스크가 실패하는 경우에 대비하기 위해 파일 블록은 여러 장비에 복제된다. 복제는 단순히 여러 장비에 동일한 데이터를 복사하는 방식이 있고, 리드 솔로몬 코드(Reed-Solomon code) 와 같은 삭제 코딩 방식을 사용해 데이터 전체를 복제하는 것보다 작은 부담으로 손실된 데이터를 복제하는 경우도 있다.

HDFS는 확장성이 뛰어나다. HDFS를 이용한 데이터 저장과 접근은 범용 하드웨어와 오픈소스 소프트웨어를 사용하기 때문에 비용이 저렴하다. 현재 이 책을 쓰는 시점에 가장 큰 HDFS는 수만 대의 장비를 묶어 실행 중이고 용량은 수백 페타바이트에 달한다.

### 맵리듀스 작업 실행하기

다음과 같은 과정으로 실행된다.

1. 입력 파일을 읽는다. 레코드로 쪼갠다. (유닉스 예제의 각 로그 줄)
2. 각 입력 레코드마다 매퍼 함수를 호출해 키와 값을 추출한다. (awk '{print $7})
3. 키를 기준으로 키-값을 쌍을 모두 정렬한다. (첫 번째 sort)
4. 정렬된 키-값 쌍 전체를 대상으로 리듀스 함수를 호출한다. 같은 키가 여러 번 등장했다면 정렬 과정에서 해당 키-값 쌍은 서로 인접한다. 그래서 같은 키를 가지는 값들을 메모리 상에 유지하지 않고도 쉽게 결합할 수 있다. (uniq -c)

1단계는 파일을 나누어 레코드를 만든다
2단계는 사용자가 작성한 **맵** 코드를 호출한다.
3단계는 정렬 단계로, 매퍼의 출력이 리듀스로 들어가기 전에 이미 정렬되어 있다.
4단계는 사용자가 작성한 **리듀스**가 호출된다.

따라서 사용자는 매퍼와 리듀서를 작성해야 한다.

> 매퍼
> 모든 입력 레코드마다 한 번씩만 호출된다. 매퍼는 입력 레코드로부터 키와 값을 추출한다. 각 입력으로부터 생성하는 키-값 쌍은 빈 쌍을 포함해 원하는 만큼 생성 가능하다.

> 리듀서
> 매퍼가 생산한 키-값 쌍을 받아 같은 키를 가진 레코드를 모으고, 해당 값의 집합을 반복해 리듀서 함수를 호출한다. 리듀서는 출력 레코드를 생산한다.

맵리듀스에서 두 번째 정렬이 필요하다면 두 번째 맵리듀스 작업을 구현하면 된다. 이 때는 첫 번째 작업의 출력을 두 번째 작업의 입력으로 사용한다. 이런 관점에서 매퍼는 정렬에 적합한 형태로 데이터를 준비하고, 리듀서는 정렬된 데이터를 가공하는 역할을 한다.

### 맵리듀스의 분산 실행

![mapReduce]({{ site.url }}/asset/DS-10-1.png)

- 각 입력 파일은 보통 크기가 수백 메가바이트에 달한다. 따라서 매퍼 입력 파일의 복제본이 있는 장비에 cpu 와 메모리가 충분하다면, 맵리듀스 스케쥴러는 입력 파일이 있는 장비에서 작업을 수행하려고 한다.
    + 다른 노드로 데이터를 옮기면 네트워크 자원을 점유하고 입력 파일을 복사해야 하기 때문
- 대부분의 경우 맵 테스크에서 실행될 애플리케이션 코드는 작업이 할당된 장비에 아직 존재하지 않음
    + 맵리듀스 프레임워크가 작업을 수행하기에 적절한 장비로 코드를 복사한다(예를 들면 Jar 파일). 복사가 끝나면 장비에서 매퍼 테스크가 시작된다.
- 리듀스 측 연산도 파티셔닝된다.
    + 맵리듀스 프레임워크는 같은 키의 리듀스 연산은 같은 노드에서 처리되는 것을 보장하는데, 이를 위해 키의 해시값을 사용한다.

키-값 쌍이 정렬되어야 하지만 데이터가 너무 크기 때문에 다음과 같은 방법을 사용한다.

1. 매퍼는 로직에 맞춰 키-값 쌍을 생성한다.
2. 매퍼는 키를 기준으로 해시값을 구하여 어떤 리듀서로 보내는지 확인한다.
3. 매퍼는 키를 기준으로 정렬하여 매퍼의 로컬 디스크에 기록한다.
4. 맵리듀스 스케쥴러는 리듀서에게 키를 가져올 수 있다고 알려준다.
5. 리듀서는 매퍼를 돌면서 정렬된 키-값 쌍을 다운로드한다.

이 과정을 **셔플** 이라고 한다. 맵리듀스에서 셔플은 임의로 섞는 게 아니다.

### 맵리듀스 워크플로

맵리듀스 작업 하나로 구할 수 있는 데이터는 제한적이다. 따라서, 여러 개의 맵리듀스를 엮어서 워크플로를 구성하곤 한다. 즉, 한 맵리듀스 작업의 출력을 다른 맵리듀스의 입력으로 사용하는 것이다.

하둡 맵리듀스는 워크플로를 제공하지 않기 때문에, 작업은 디렉토리 이름을 통해 압묵적으로 연결된다. 첫 번째 맵리듀스의 결과는 폴더에 저장되고, 두 번째 작업은 해당 디렉토리를 입력으로 사용하는 것이다. 맵리듀스의 관점에서는 두 작업은 완전 독립적이다.

이를 지원하기 위해 여러 스케쥴러개 개발되었다. 우지, 아즈카반, 루이지, 에어플로, 핀볼 등이 있다. 추천 시스템을 구성하기 위한 맵리듀스 워크플로는 50개에서 100개가 일반적이다. 따라서 이를 지원하기 위한 도구도 필요하다. 피그, 하이브, 캐스케이딩, 크런치, 플룸자바 같은 다양한 하둡용 고수준 도구는 다중 맵리듀스를 서로 적절하게 자동으로 엮어 워크플로를 생성한다.

### 리듀스 사이드 조인과 그룹화




