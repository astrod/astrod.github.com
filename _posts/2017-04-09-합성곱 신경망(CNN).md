---
title: "합성곱 신경망(CNN)"
tags:
- deep_learning
---

# 들어가며
이 글은 <<밑바닥부터 시작하는 딥러닝>> 7장 합성곱 신경망(CNN) 의 내용을 정리한 포스팅입니다. 이 포스팅의 내용을 이해하려면 이 책의 이전 장을 알고 있는 게 좋습니다.
아니면, 딥러닝 신경망이 어떻게 구성되는지 대략적으로 알고 계신다면, 내용 이해에 도움이 될 거라고 생각합니다.

# 합성곱 신경망(CNN)
CNN은 Convolutional neural network의 약자로, 합성곱 신경망이라는 의미입니다. CNN은 이미지 인식과 음성 인식 등 다양한 곳에서 사용되는데요. 특히 이미지 인식 분야에서 광범위하게 사용되고 있습니다.
이 장에서는 CNN의 메커니즘을 설명하고 파이썬으로 어떻게 구현하는지 확인해 볼 예정입니다.

## 전체 구조
- CNN도 일반적인 딥러닝과 구조는 같습니다.
    - 즉 어파인 연산 > 활성화 함수(시그모이드 or ReLU) 의 레이여가 연속되어 있는 구조입니다.
    - 다만 합성곱 계층과 풀링 계층이 새롭게 등장합니다.

지금까지 신경망의 구조는 다음과 같았습니다.

<div class="mermaid">
graph LR;
    Affine1 -->ReLU1
    ReLU1 --> Affine2
    Affine2 -->ReLU2
    ReLU2 --> Affine3
    Affine3 -->SoftMax
</div>

CNN 또한 비슷합니다. 다만 새로운 계층이 추가됩니다.

<div class="mermaid">
graph LR;
    Conv1 -->ReLU1
    ReLU1 --> Pooling1
    Pooling1 --> Conv2
    Conv2 -->ReLU2
    ReLU2 --> Pooling2
    Pooling2 --> Affine3
    Affine3 --> softmax
</div>

새롭게 합성곱 계층(Conv)와 폴링 계층(Pooling) 이 추가됩니다. 특징은 다음과 같습니다.

- 폴링 계층은 생략될 수도 있다.
- 출력에 가까운 층에서는 Affine - ReLU 레이어를 사용할수도 있다.
- 마지막 출력 계층에서는 Affine - Softmax 조합을 사용할수도 있다.

## 합성곱 계층(Conv)
지금까지 본 완전연결 신경망에서는 Affine 계층을 사용하였습니다. 이 신경망에서는, 인접하는 계층의 뉴런이 모두 연결되고 출력의 수는 임의로 정할 수 있습니다.
이 방식은 문제점이 있습니다. 바로 데이터의 형상이 무시된다는 것입니다.

예를 들면 MNIST 데이터셋은 (1, 28, 28)의 3차원 데이터셋이지만, 데이터를 입력할 때는 위의 픽셀을 일렬로 세운 1 * 28 * 28 = 784개의 데이터를 Affine 계층에 입력했습니다.
이미지는 3차원 형상이며, 픽셀 사이의 관계에도 여러 가지 정보가 담겨 있습니다. 공간적으로 가까운 픽셀은 값이 비슷하다던지, RGB 각 채널은 밀접하게 관련되어 있다던지 하는 데이터입니다.
완전연결 신경망에서는 위의 성질을 무시하게 됩니다. 그러나, 합성곱 계층은 형상을 유지합니다. 이미지도 3차원 데이터로 입력받으며 마찬가지로 다음 계층에도 3차원 데이터로 전달합니다.

합성곱 계층에서 사용하는 용어 정리를 간단하게 하고 넘어가겠습니다. 이 용어는 앞으로 여러 번 나올 예정입니다.

- 특징 맵(feature map) : 합성곱 계층의 입출력 데이터
- 입력 특징 맵(input feature map) : 합성곱 계층의 입력 데이터
- 출력 특징 맵(output feature map) : 합성곱 계층의 출력 데이터

### 합성곱 연산
합성곱 연산은 이미지 처리에서 말하는 필터 연산에 해당합니다. 구체적인 예를 보며 설명하겠습니다.

| 1 | 2 | 3 | 0 |                     
|---|---|---|---|
| 0 | 1 | 2 | 3 |                     
| 3 | 0 | 1 | 2 |
| 2 | 3 | 0 | 1 |

이 데이터와

| 2 | 0 | 1 |                     
|---|---|---|
| 0 | 1 | 2 |                     
| 1 | 0 | 2 |

이 데이터를 합성곱으로 처리한다고 가정하겠습니다. 이 데이터에서 입력 데이터는 가로, 세로 방향의 형상이고 필터 또한 가로 세로 방향의 형상입니다. 이를 (4, 4) 그리고 (3,3) 이라고 표현합니다. 문헌에 따라 필터를 커널이라고 부르기도 합니다.

합성곱 연산은 필터의 윈도우를 일정 간격으로 이동시키면서 수행합니다. 순서는 다음과 같습니다.

1. 필터의 (0, 0) 부분을 입력 데이터의 (0,0) 부분에 겹칩니다.
2. 필터와 겹친 부분 데이터를 대응하는 원소끼리 곱해서, 모두 더합니다. 이 과정을 단일 곱샙 누산이라 합니다.
3. 필터를 일정 거리만큼 우측으로 이동시킵니다. 필터의 우측 끝이 입력 데이터의 마지막과 겹친다면, 다음 라인으로 이동시킵니다.
4. 위의 과정을 필터가 입력 데이터의 마지막 부분에 도달할때까지 반복합니다.

위의 데이터를 가지고 한번 연산을 수행해 보겠습니다. 3번의 일정 거리는 1로 가정하겠습니다.

1. 필터의 좌상단을 입력 데이터의 (0,0)에 겹치고 연산을 수행합니다.
- 1*2 + 0*2 + 1*3 + 0*0 + 1*1 + 2*2 + 1*3 + 0*3 +2*1 = 15
2. 필터를 우측으로 한 칸 이동시킨 뒤,  대응하는 원소끼리 곱한 후 연산을 수행합니다. 
- 2*2 + 0*3+1*0 +0*1 + 1*2 + 2*3 +1*0 + 0*1 + 2*2 = 16
3. 필터가 우측 끝에 도달했으므로, 아래로 한칸 이동시킨 뒤 가장 좌측에 붙입니다. 입력 데이터의 (1, 0) 위치입니다.
4. 연산 수행후 우측으로 한 칸 이동시킵니다. 연산을 수행합니다.
5. 필터가 우측 끝 마지막 부분에 도달하였으므로 연산을 종료합니다.

필터연산을 거친 데이터를 나타내면 다음과 같은 모양이 됩니다.

| 15 | 16 |
|----|----|
| 6  | 15 |

완전연결 신경망에는 편항이 존재하는데, CNN에도 편향이 존재합니다. 연산을 다 수행했다면 편항을 결과값의 모든 원소에 더해줍니다. 만약, 편향이 3이라면 최종 결과값은 다음과 같을 것입니다.

| 18 | 19 |
|----|----|
| 9  | 18 |

### 패딩
합성곱 연산을 수행하기 전에, 데이터 주변을 특정 값으로 채우기도 합니다. 이를 패딩이라고 하며 합성곱 연산에서는 자주 사용하는 기법입니다.





